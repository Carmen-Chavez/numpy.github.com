<!doctype html><html lang=pt data-colorscheme=light><head><meta name=description content="Por que NumPy? Arrays n-dimensionais poderosas. Ferramentas para computação numérica. Interoperabilidade. Alto desempenho. Código aberto."><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=x-ua-compatible content="ie=edge"><title>NumPy - Estudo de Caso: Estimativa de Pose 3D com DeepLabCut</title>
<link rel=icon href=/images/favicon.ico><link rel=stylesheet type=text/css href=/theme-css/sphinx-design/index.scss.min.acf226aa2ff428a500491b1393bef415c3883113dac542174f5814fba5532592.css integrity="sha256-rPImqi/0KKUASRsTk770FcOIMRPaxUIXT1gU+6VTJZI="><link rel=stylesheet type=text/css href=/theme-css/pst/bootstrap.scss.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css integrity="sha256-47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU="><link rel=stylesheet type=text/css href=/theme-css/pst/pydata-sphinx-theme.scss.min.1032a66ba1e0ab03bfcbfd265dce1d831879c5ea9d57e8575a68eeeb887b617e.css integrity="sha256-EDKma6HgqwO/y/0mXc4dgxh5xeqdV+hXWmju64h7YX4="><link rel=stylesheet type=text/css href=/theme-css/spht/index.scss.min.ad03de1683bb39a0d1b31395797b97188e59cda6d778c0671a99db0b4fb799a9.css integrity="sha256-rQPeFoO7OaDRsxOVeXuXGI5ZzabXeMBnGpnbC0+3mak="><link rel=stylesheet type=text/css href=/css/tabs.scss.min.549aba196cc14bca7747a312ff35df0aa1f486b740c19ee0c88aaa721fb8c2e1.css integrity="sha256-VJq6GWzBS8p3R6MS/zXfCqH0hrdAwZ7gyIqqch+4wuE="><link rel=stylesheet href=/theme-css/backtotop.min.af4a1eb2a3e4e5ca38353a8320dafc9b1e1fd2edd480caa5fff0ae4e751d991c.css integrity="sha256-r0oesqPk5co4NTqDINr8mx4f0u3UgMql//CuTnUdmRw="><link rel=stylesheet href=/theme-css/bulma.min.f488b160722c9b7a2a760c03808dc8df5173e6c9dd25cb7481451ddb3c4f35dc.css integrity="sha256-9IixYHIsm3oqdgwDgI3I31Fz5sndJct0gUUd2zxPNdw="><link rel=stylesheet href=/theme-css/code-highlight.min.d0bd96ff1dbeb4b62536da5935b92af5cd7edb6d6f52b316d721e62078d9f089.css integrity="sha256-0L2W/x2+tLYlNtpZNbkq9c1+221vUrMW1yHmIHjZ8Ik="><link rel=stylesheet href=/theme-css/content.min.1de9b096ffc099fee4b538589fea6b622be33d69de64c451e11f2c91476029c5.css integrity="sha256-Hemwlv/Amf7ktThYn+prYivjPWneZMRR4R8skUdgKcU="><link rel=stylesheet href=/theme-css/dark-mode.min.1a7d04742ddf658331233b701507a0124657cbf45e02c672c061955181de6dde.css integrity="sha256-Gn0EdC3fZYMxIztwFQegEkZXy/ReAsZywGGVUYHebd4="><link rel=stylesheet href=/theme-css/footer.min.4be63c4d5628cb485efcfa5c9475fa1daa18933eb83741a2ca2bcd444ec270a2.css integrity="sha256-S+Y8TVYoy0he/PpclHX6HaoYkz64N0GiyivNRE7CcKI="><link rel=stylesheet href=/theme-css/hero.min.aa8286fd7d31d78e297e71594436c47b17d4f28660fd16f2b252e3f55fa500be.css integrity="sha256-qoKG/X0x144pfnFZRDbEexfU8oZg/RbyslLj9V+lAL4="><link rel=stylesheet href=/theme-css/lists.min.83821789384ebadc1a1ff75ef9f4b29ba53fe45eb30a46a228aa55772a393396.css integrity="sha256-g4IXiThOutwaH/de+fSym6U/5F6zCkaiKKpVdyo5M5Y="><link rel=stylesheet href=/theme-css/navbar.min.c15f7eadb5a7e1532309c04d94e1b0099d4fa75aaded30829bbfd21ebdb51ad5.css integrity="sha256-wV9+rbWn4VMjCcBNlOGwCZ1Pp1qt7TCCm7/SHr21GtU="><link rel=stylesheet href=/theme-css/news.min.8875ffae62ae22741a27025581fcb3341c18442be06bf132e45f8d6027692876.css integrity="sha256-iHX/rmKuInQaJwJVgfyzNBwYRCvga/Ey5F+NYCdpKHY="><link rel=stylesheet href=/theme-css/posts.min.9505f87d5973f3f08c99c613c0781b3a42411f4795657e8da7ef29c7ad37c23d.css integrity="sha256-lQX4fVlz8/CMmcYTwHgbOkJBH0eVZX6Np+8px603wj0="><link rel=stylesheet href=/theme-css/search.min.ee3423de82ad5535fd375aa47bc4fe618ecaa5d10eb0b68fe6dfc85a78790676.css integrity="sha256-7jQj3oKtVTX9N1qke8T+YY7KpdEOsLaP5t/IWnh5BnY="><link rel=stylesheet href=/theme-css/shortcuts.min.f90addf0a2a3c4e075eb5c3c78e4cc27d9b4fba18a02a17808695212762224c1.css integrity="sha256-+Qrd8KKjxOB161w8eOTMJ9m0+6GKAqF4CGlSEnYiJME="><link rel=stylesheet href=/theme-css/styles.min.00c75e5e25cb21123ca151cb4f4a130891157870829d91cefa425316ecf23de2.css integrity="sha256-AMdeXiXLIRI8oVHLT0oTCJEVeHCCnZHO+kJTFuzyPeI="><link rel=stylesheet href=/theme-css/tables.min.7a44b6bd698323dd3d379b714bd534132e76bf4ba0d3dec61997a8d9ba9db5fb.css integrity="sha256-ekS2vWmDI909N5txS9U0Ey52v0ug097GGZeo2bqdtfs="><link rel=stylesheet href=/theme-css/tabs.min.8884c317231b5f2331b2fd9f65e4f7900fe9124aafae93b78cef175960289683.css integrity="sha256-iITDFyMbXyMxsv2fZeT3kA/pEkqvrpO3jO8XWWAoloM="><link rel=stylesheet href=/theme-css/vars.min.3d537d14ea6e6fb59012fa9d357adf4b209dab8c2535fb94ab37afb6a37020fd.css integrity="sha256-PVN9FOpub7WQEvqdNXrfSyCdq4wlNfuUqzevtqNwIP0="><link rel=stylesheet href=/css/casestudies.min.92b0bafc1e58181b02c23f14b861767269e505eadc85a123b4eb79e2527bf2e0.css integrity="sha256-krC6/B5YGBsCwj8UuGF2cmnlBerchaEjtOt54lJ78uA="><link rel=stylesheet href=/css/custom.min.cf0f0187caa046832f55197d09d0ad54a98eebc7758bbb354fb1c8fb8541b5bb.css integrity="sha256-zw8Bh8qgRoMvVRl9CdCtVKmO68d1i7s1T7HI+4VBtbs="><link rel=stylesheet href=/css/mailchimp.min.96f403ea4c8be10747beb4c33a219da2fa8234a3b98882983bd2569da8eeb9e1.css integrity="sha256-lvQD6kyL4QdHvrTDOiGdovqCNKO5iIKYO9JWnajuueE="><link rel=stylesheet href=/css/shell.min.173478d133f6f5990705f3ed2f48714422de15754d813df6aa2a047bf62a51da.css integrity="sha256-FzR40TP29ZkHBfPtL0hxRCLeFXVNgT32qioEe/YqUdo="><script src=https://code.jquery.com/jquery-3.7.1.min.js></script><link rel=alternate hreflang=en href=/case-studies/deeplabcut-dnn/ title=English><link rel=alternate hreflang=ja href=/ja/case-studies/deeplabcut-dnn/ title="日本語 (Japanese)"><link rel=alternate hreflang=es href=/es/case-studies/deeplabcut-dnn/ title=Español><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://numpy.org/images/numpy-image.jpg"><meta name=twitter:title content="Estudo de Caso: Estimativa de Pose 3D com DeepLabCut"><meta name=twitter:description content="Análise de movimentos de mãos de camundongos usando DeepLapCut#
(Fonte: www.deeplabcut.org ) Software de código aberto está acelerando a Biomedicina. DeepLabCut permite a análise automática de vídeos de comportamento animal usando Deep Learning. —Alexander Mathis, Professor Assistente, École polytechnique fédérale de Lausanne (EPFL)
Sobre o DeepLabCut# DeepLabCut é uma toolbox de código aberto que permite que pesquisadores de centenas de instituições em todo o mundo rastreiem o comportamento de animais de laboratório, com muito poucos dados de treinamento, mas com precisão no nível humano. Com a tecnologia DeepLabCut, cientistas podem aprofundar a compreensão científica do controle motor e do comportamento em diversas espécies animais e escalas temporais."></head><body><nav id=nav class=navbar role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/pt/><img class=navbar-logo src=/images/logo.svg alt="%!s(<nil>) logo"><div class=navbar-logo-text>NumPy</div></a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=navbar-menu><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=navbar-menu class=navbar-menu><div class=navbar-end><a href=/pt/install class=navbar-item>Instalação
</a><a href=https://numpy.org/doc/stable class=navbar-item>Documentação
</a><a href=/pt/learn class=navbar-item>Aprenda
</a><a href=/pt/community class=navbar-item>Comunidade
</a><a href=/pt/about class=navbar-item>Sobre
</a><a href=/pt/news class=navbar-item>Notícias
</a><a href=/pt/contribute class=navbar-item>Contribuir</a><div class="navbar-item has-dropdown"><a aria-label="Select language" class=navbar-link>Português</a><div class=navbar-dropdown><a href=/case-studies/deeplabcut-dnn/ class=navbar-item>English
</a><a href=/ja/case-studies/deeplabcut-dnn/ class=navbar-item>日本語 (Japanese)
</a><a href=/es/case-studies/deeplabcut-dnn/ class=navbar-item>Español</a></div></div></div></div></div></nav><section class=content-padding><div class=content-container><nav aria-label=Breadcrumb><ul id=breadcrumbs class=bd-breadcrumbs><li class="breadcrumb-item breadcrumb-home"><a href=/pt/ class=nav-link aria-label=Home><i class="fas fa-home"></i></a></li><li class=breadcrumb-item><a href=/pt/case-studies/ class=nav-link>Case-Studies</a></li><li class="breadcrumb-item active" aria-current=page>Estudo de Caso: Estimativa de Pose 3D com DeepLabCut</li></ul></nav><h1>Estudo de Caso: Estimativa de Pose 3D com DeepLabCut</h1><div><figure class=align-default id=id000><img src=/images/content_images/cs/mice-hand.gif alt=micehandanim class=align-center><figcaption><strong class=caption-title>Análise de movimentos de mãos de camundongos usando DeepLapCut</strong><a class=headerlink href=#id000 title="Link to this image">#</a><br><a href=http://www.mousemotorlab.org/deeplabcut>(Fonte: www.deeplabcut.org )</a><p><span class=caption-text></span></figcaption></figure><blockquote cite=https://news.harvard.edu/gazette/story/newsplus/harvard-researchers-awarded-czi-open-source-award/><p>Software de código aberto está acelerando a Biomedicina. DeepLabCut permite a análise automática de vídeos de comportamento animal usando Deep Learning.</p><p class=attribution>—Alexander Mathis, <em>Professor Assistente, École polytechnique fédérale de Lausanne</em> (<a href=https://www.epfl.ch/en/>EPFL</a>)</p></blockquote><h2 id=sobre-o-deeplabcut>Sobre o DeepLabCut<a class=headerlink href=#sobre-o-deeplabcut title="Link to this heading">#</a></h2><p><a href=https://github.com/DeepLabCut/DeepLabCut>DeepLabCut</a> é uma toolbox de código aberto que permite que pesquisadores de centenas de instituições em todo o mundo rastreiem o comportamento de animais de laboratório, com muito poucos dados de treinamento, mas com precisão no nível humano. Com a tecnologia DeepLabCut, cientistas podem aprofundar a compreensão científica do controle motor e do comportamento em diversas espécies animais e escalas temporais.</p><p>Várias áreas de pesquisa, incluindo a neurociência, a medicina e a biomecânica, utilizam dados de rastreamento da movimentação de animais. A DeepLabCut ajuda a compreender o que os seres humanos e outros animais estão fazendo, analisando ações que foram registradas em vídeo. Ao usar automação para tarefas trabalhosas de monitoramento e marcação, junto com análise de dados baseada em redes neurais profundas, a DeepLabCut garante que estudos científicos envolvendo a observação de animais como primatas, camundongos, peixes, moscas etc. sejam mais rápidos e precisos.</p><figure class=align-default id=id002><img src=/images/content_images/cs/race-horse.gif alt=horserideranim class=align-center><figcaption><strong class=caption-title>Pontos coloridos rastreiam as posições das partes do corpo de um cavalo de corrida</strong><a class=headerlink href=#id002 title="Link to this image">#</a><br>(Fonte: Mackenzie Mathis)<p><span class=caption-text></span></figcaption></figure><p>O rastreamento não invasivo dos animais pela DeepLabCut através da extração de poses é crucial para pesquisas científicas em domínios como a biomecânica, genética, etologia e neurociência. Medir as poses dos animais de maneira não invasiva através de vídeo - sem marcadores - com fundos dinâmicos é computacionalmente desafiador, tanto tecnicamente quanto em termos de recursos e dados de treinamento necessários.</p><p>A DeepLabCut permite que pesquisadores façam estimativas de poses para os sujeitos, permitindo que se possa quantificar de maneira eficiente seus comportamentos através de um conjunto de ferramentas de software baseado em Python. Com a DeepLabCut, pesquisadores podem identificar quadros (<em>frames</em>) distintos em vídeos e rotular digitalmente partes específicas do corpo em alguns quadros com uma GUI especializada. A partir disso, a arquitetura de estimação de poses baseada em deep learning da DeepLabCut aprende a selecionar essas mesmas características no resto do vídeo e em outros vídeos similares. A ferramenta funciona para várias espécies de animais, desde animais comuns em laboratórios, como moscas e camundongos, até os mais incomuns, como <a href=https://www.technologynetworks.com/neuroscience/articles/interview-a-deeper-cut-into-behavior-with-mackenzie-mathis-327618>guepardos</a>.</p><p>A DeepLabCut usa um princípio chamado <a href=https://arxiv.org/pdf/1909.11229>aprendizado por transferência (<em>transfer learning</em>)</a>, o que reduz enormemente a quantidade de dados de treinamento necessários e acelera a convergência do período de treinamento. Dependendo das suas necessidades, usuários podem escolher diferentes arquiteturas de rede que forneçam inferência mais rápida (por exemplo, MobileNetV2), e que também podem ser combinadas com feedback experimental em tempo real. A DeepLabCut usou originalmente os detectores de features de uma arquitetura de alto desempenho para estimativa de poses humanas, chamada <a href=https://arxiv.org/abs/1605.03170>DeeperCut</a>, que inspirou seu nome. O pacote foi significativamente alterado para incluir mais arquiteturas, métodos de ampliação e uma experiência de usuário completa no front-end. Além de possibilitar experimentos biológicos em grande escala, DeepLabCut fornece capacidades ativas de aprendizado para que os usuários possam aumentar o conjunto de treinamento ao longo do tempo, para incluir casos particulares e tornar seu algoritmo de estimativa de poses robusto no seu contexto específico.</p><p>Recentemente, foi introduzido o <a href=http://www.mousemotorlab.org/dlc-modelzoo>modelo DeepLabCut zoo</a>, que proporciona modelos pré-treinados para várias espécies e condições experimentais, desde a análise facial em primatas até à posição de cães. Isso pode ser executado na nuvem, por exemplo, sem qualquer rotulagem de novos dados ou treinamento em rede neural, e não é necessária nenhuma experiência em programação.</p><h3 id=principais-objetivos-e-resultados>Principais Objetivos e Resultados<a class=headerlink href=#principais-objetivos-e-resultados title="Link to this heading">#</a></h3><ul><li><p><strong>Automação da análise de poses animais para estudos científicos:</strong></p><p>O objetivo principal da tecnologia DeepLabCut é medir e rastrear a postura dos animais em várias configurações. Esses dados podem ser usados, por exemplo, em estudos de neurociência para entender como o cérebro controla o movimento, ou para elucidar como os animais interagem socialmente. Pesquisadores observaram que <a href=https://www.biorxiv.org/content/10.1101/457242v1>desempenho é 10 vezes melhor</a> com o DeepLabCut. Poses podem ser inferidas off-line em até 1200 quadros por segundo (FPS).</p></li><li><p><strong>Criação de um kit de ferramentas Python fácil de usar para estimativa de poses:</strong></p><p>DeepLabCut queria compartilhar sua tecnologia de estimativa de poses animal na forma de uma ferramenta simples de usar que pudesse ser adotada pelos pesquisadores facilmente. Assim, criaram um conjunto de ferramentas em Python completo e fácil de usar, também com recursos de gerenciamento de projeto. Isso permite não apenas a automação de estimação de poses, mas também o gerenciamento do projeto de ponta a ponta, ajudando o usuário do DeepLabCut Toolkit desde a fase de coleta para criar fluxos de dados compartilháveis e reutilizáveis.</p><p>Seu <a href=https://github.com/DeepLabCut/DeepLabCut>conjunto de ferramentas</a> agora está disponível como software de código aberto.</p><p>Um fluxo de trabalho típico na DeepLabCut inclui:</p><ul><li>criação e refinamento de conjuntos de treinamento por meio de aprendizagem ativa</li><li>criação de redes neurais personalizadas para animais e cenários específicos</li><li>código para inferência em larga escala em vídeos</li><li>inferências de desenho usando ferramentas integradas de visualização</li></ul></li></ul><figure class=align-center id=id003><img src=/images/content_images/cs/deeplabcut-toolkit-steps.png alt=dlcsteps class=align-center><figcaption><strong class=caption-title>Passos na estimação de poses com DeepLabCut</strong><a class=headerlink href=#id003 title="Link to this image">#</a><br><a href=https://twitter.com/DeepLabCut/status/1198046918284210176/photo/1>(Fonte: DeepLabCut)</a><p><span class=caption-text></span></figcaption></figure><h3 id=desafios>Desafios<a class=headerlink href=#desafios title="Link to this heading">#</a></h3><ul><li><p><strong>Velocidade</strong></p><p>Processamento rápido de vídeos de animais para medir seu comportamento e, ao mesmo tempo, tornar os experimentos científicos mais eficientes e precisos. Extrair poses animais detalhadas para experimentos em laboratório, sem marcadores, sobre fundos dinâmicos, pode ser desafiador tanto tecnicamente quanto em termos de recursos e dados de treinamento necessários. Criar uma ferramenta que seja fácil de usar sem necessidade de habilidades como expertise em visão computacional que permita aos cientistas fazerem pesquisa em contextos mais próximos do mundo real é um problema não-trivial a ser solucionado.</p></li><li><p><strong>Combinatória</strong></p><p>Combinatória envolve a junção e integração de movimentos de múltiplos membros em um comportamento animal único. Reunir pontos-chave e suas conexões em movimentos animais individuais e encadeá-los em função do tempo é um processo complexo que exige análise numérica intensa, especialmente nos casos de rastreio de múltiplos animais em vídeos experimentais.</p></li><li><p><strong>Processamento de dados</strong></p><p>Por último, mas não menos importante, manipulação de matrizes - processar grandes conjuntos de matrizes correspondentes a várias imagens, tensores alvo e pontos-chave é bastante desafiador.</p></li></ul><figure class=align-center id=id004><img src=/images/content_images/cs/pose-estimation.png alt=challengesfig class=align-center><figcaption><strong class=caption-title>Estimação de poses e complexidade</strong><a class=headerlink href=#id004 title="Link to this image">#</a><br><a href=https://www.biorxiv.org/content/10.1101/476531v1.full.pdf>(Fonte: Mackenzie Mathis)</a><p><span class=caption-text></span></figcaption></figure><h2 id=o-papel-da-numpy-nos-desafios-da-estimação-de-poses>O papel da NumPy nos desafios da estimação de poses<a class=headerlink href=#o-papel-da-numpy-nos-desafios-da-estimação-de-poses title="Link to this heading">#</a></h2><p>NumPy supre a principal necessidade da tecnologia DeepLabCut de cálculos numéricos de alta velocidade para análises comportamentais. Além da NumPy, DeepLabCut emprega várias bibliotecas Python que usam a NumPy como sua base, tais como <a href=https://www.scipy.org>SciPy</a>, <a href=https://pandas.pydata.org>Pandas</a>, <a href=https://matplotlib.org>matplotlib</a>, <a href=https://github.com/tensorpack/tensorpack>Tensorpack</a>, <a href=https://github.com/aleju/imgaug>imgaug</a>, <a href=https://scikit-learn.org/stable/>scikit-learn</a>, <a href=https://scikit-image.org>scikit-image</a> e <a href=https://www.tensorflow.org>Tensorflow</a>.</p><p>As seguintes características da NumPy desempenharam um papel fundamental para atender às necessidades de processamento de imagens, combinatória e cálculos rápidos nos algoritmos de estimação de pose na DeepLabCut:</p><ul><li>Vetorização</li><li>Operações em arrays com máscaras</li><li>Álgebra linear</li><li>Amostragem aleatória</li><li>Reordenamento de matrizes grandes</li></ul><p>A DeepLabCut utiliza as capacidades de manipulação de arrays da NumPy em todo o fluxo de trabalho oferecido pelo seu conjunto de ferramentas. Em particular, a NumPy é usada para amostragem de quadros distintos para serem rotulados com anotações humanas e para escrita, edição e processamento de dados de anotação. Dentro da TensorFlow, a rede neural é treinada pela tecnologia DeepLabCut em milhares de iterações para prever as anotações verdadeiras dos quadros. Para este propósito, densidades de alvo (<em>scoremaps</em>) são criadas para colocar a estimativa como um problema de tradução de imagem a imagem. Para tornar as redes neurais robustas, o aumento de dados é empregado, o que requer o cálculo de scoremaps alvo sujeitos a várias etapas geométricas e de processamento de imagem. Para tornar o treinamento rápido, os recursos de vectorização da NumPy são utilizados. Para inferência, as previsões mais prováveis de scoremaps alvo precisam ser extraídas e é necessário &ldquo;vincular previsões para montar animais individuais&rdquo; de maneira eficiente.</p><figure class=align-default id=id005><img src=/images/content_images/cs/deeplabcut-workflow.png alt=workflow class=align-center><figcaption><strong class=caption-title>Fluxo de dados DeepLabCut</strong><a class=headerlink href=#id005 title="Link to this image">#</a><br><a href=https://www.researchgate.net/figure/DeepLabCut-work-flow-The-diagram-delineates-the-work-flow-as-well-as-the-directory-and_fig1_329185962>(Fonte: Mackenzie Mathis)</a><p><span class=caption-text></span></figcaption></figure><h2 id=resumo>Resumo<a class=headerlink href=#resumo title="Link to this heading">#</a></h2><p>Observação e descrição eficiente do comportamento é uma peça fundamental da etologia, neurociência, medicina e tecnologia modernas. <a href=http://orga.cvss.cc/wp-content/uploads/2019/05/NathMathis2019.pdf>DeepLabCut</a> permite que os pesquisadores estimem a pose do sujeito, permitindo efetivamente que o seu comportamento seja quantificado. Com apenas um pequeno conjunto de imagens de treinamento, o conjunto de ferramentas em Python da DeepLabCut permite treinar uma rede neural tão precisa quanto a rotulagem humana, expandindo assim sua aplicação para não só análise de comportamento dentro do laboratório, mas também potencialmente em esportes, análise de locomoção, medicina e estudos sobre reabilitação. Desafios complexos em combinatória e processamento de dados enfrentados pelos algoritmos da DeepLabCut são tratados através do uso de recursos de manipulação de matriz do NumPy.</p><figure class=align-default id=id006><img src=/images/content_images/cs/numpy_dlc_benefits.png alt="numpy benefits" class=align-center><figcaption><strong class=caption-title>Recursos chave do NumPy utilizados</strong><a class=headerlink href=#id006 title="Link to this image">#</a><br><p><span class=caption-text></span></figcaption></figure></div></div><div id=shortcuts-container><div id=shortcuts><div id=shortcuts-header><i class="fa-solid fa-list"></i> On this page</div></div></div></section><div id=backtotop><a href=# id=backtotop-color><i class="fa-solid fa-arrow-up"></i></a></div><footer id=footer><div class=container><div id=footer-columns><div id=footer-logo-column><img id=footer-logo src=/images/logo.svg alt="NumPy logo. "></div><div class=footer-column><div class=footer-item><a href=/pt/install>Instalação</a></div><div class=footer-item><a href=https://numpy.org/doc/stable>Documentação</a></div><div class=footer-item><a href=/pt/learn>Aprenda</a></div><div class=footer-item><a href=/pt/citing-numpy>Citando o Numpy</a></div><div class=footer-item><a href=https://numpy.org/neps/roadmap.html>Roadmap</a></div></div><div class=footer-column><div class=footer-item><a href=/pt/about>Sobre</a></div><div class=footer-item><a href=/pt/community>Comunidade</a></div><div class=footer-item><a href=/pt/user-surveys>Pesquisas de usuário</a></div><div class=footer-item><a href=/pt/contribute>Contribuir</a></div><div class=footer-item><a href=/pt/code-of-conduct>Código de Conduta</a></div></div><div class=footer-column><div class=footer-item><a href=/pt/gethelp>Ajuda</a></div><div class=footer-item><a href=/pt/terms>Termos de uso (EN)</a></div><div class=footer-item><a href=/pt/privacy>Privacidade</a></div><div class=footer-item><a href=/pt/press-kit>Kit de imprensa</a></div></div><div class=footer-actions>Sign up for the latest NumPy news, resources, and more<form action="https://numpy.us4.list-manage.com/subscribe/post?u=5ddd0d1d6e807900a8212481a&amp;id=287fa4253c" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class="validate sign-up-container" target=_blank novalidate><div class=sign-up-image><svg class="icon mail-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M22 6c0-1.1-.9-2-2-2H4c-1.1.0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1.0 2-.9 2-2V6zm-2 0-8 5-8-5h16zm0 12H4V8l8 5 8-5v10z"/></svg></div><input type=email name=EMAIL class="required email sign-up-input" id=mce-EMAIL aria-label="Input for email, press enter to submit" onkeypress='(event.which===13||event.keyCode===13||event.key==="Enter")&&sendThankYou()'><div class=submission-instructions>Press Enter</div><button class=signup-button onclick=sendThankYou() aria-label=Submit><svg class="icon sent-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M2.01 21 23 12 2.01 3 2 10l15 2-15 2z"/></svg></button><div id=mce-responses class=clear><div class=response id=mce-error-response style=display:none></div><div class=response id=mce-success-response style=display:none></div></div><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_5ddd0d1d6e807900a8212481a_287fa4253c tabindex=-1></div><div class=clear><input type=submit value=Subscribe name=subscribe id=mc-embedded-subscribe class=button style=display:none></div></form><div class=thank-you>Thank you! &#127881;</div><div class=community-icons><a href=https://github.com/numpy/numpy aria-label=https://github.com/numpy/numpy><svg class="icon github-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M12 .297c-6.63.0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577.0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93.0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176.0.0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22.0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22.0 1.606-.015 2.896-.015 3.286.0.315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
</a><a href=https://www.youtube.com/channel/UCguIL9NZ7ybWK5WQ53qbHng aria-label=https://www.youtube.com/channel/UCguIL9NZ7ybWK5WQ53qbHng><svg class="icon youtube-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M23.498 6.186A3.016 3.016.0 0021.376 4.05C19.505 3.545 12 3.545 12 3.545s-7.505.0-9.377.505A3.017 3.017.0 00.502 6.186C0 8.07.0 12 0 12s0 3.93.502 5.814a3.016 3.016.0 002.122 2.136c1.871.505 9.376.505 9.376.505s7.505.0 9.377-.505a3.015 3.015.0 002.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg>
</a><a href=https://twitter.com/numpy_team aria-label=https://twitter.com/numpy_team><svg class="icon twitter-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958.0 002.163-2.723c-.951.555-2.005.959-3.127 1.184A4.92 4.92.0 0011.78 8.288C7.69 8.095 4.067 6.13 1.64 3.162A4.822 4.822.0 00.974 5.637c0 1.71.87 3.213 2.188 4.096A4.904 4.904.0 01.934 9.117v.06a4.923 4.923.0 003.946 4.827 4.996 4.996.0 01-2.212.085 4.936 4.936.0 004.604 3.417A9.867 9.867.0 011.17 19.611c-.39.0-.779-.023-1.17-.067a13.995 13.995.0 007.557 2.209c9.053.0 13.998-7.496 13.998-13.985.0-.21.0-.42-.015-.63A9.935 9.935.0 0024 4.59z"/></svg></a></div><div class=copyright>&copy; 2025 NumPy team. All rights reserved.</div></div></div></div></footer></body><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin=anonymous referrerpolicy=no-referrer><script type=text/javascript src=/js/bundle.min.js></script><script type=text/javascript>setupShortcuts(maxLevel=2)</script><script defer data-domain=numpy.org src=https://views.scientific-python.org/js/script.js></script></html>