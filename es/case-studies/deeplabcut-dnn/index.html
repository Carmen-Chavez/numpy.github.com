<!doctype html><html lang=es data-colorscheme=light><head><meta name=description content="¿Por qué NumPy? Potentes arreglos n-dimensionales. Herramientas de cálculo numérico. Interoperabilidad. Rendimiento. Código abierto."><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=x-ua-compatible content="ie=edge"><title>NumPy - Caso de estudio: DeepLabCut Estimación de Postura 3D</title>
<link rel=icon href=/images/favicon.ico><link rel=stylesheet type=text/css href=/theme-css/sphinx-design/index.scss.min.acf226aa2ff428a500491b1393bef415c3883113dac542174f5814fba5532592.css integrity="sha256-rPImqi/0KKUASRsTk770FcOIMRPaxUIXT1gU+6VTJZI="><link rel=stylesheet type=text/css href=/theme-css/pst/bootstrap.scss.min.e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855.css integrity="sha256-47DEQpj8HBSa+/TImW+5JCeuQeRkm5NMpJWZG3hSuFU="><link rel=stylesheet type=text/css href=/theme-css/pst/pydata-sphinx-theme.scss.min.1032a66ba1e0ab03bfcbfd265dce1d831879c5ea9d57e8575a68eeeb887b617e.css integrity="sha256-EDKma6HgqwO/y/0mXc4dgxh5xeqdV+hXWmju64h7YX4="><link rel=stylesheet type=text/css href=/theme-css/spht/index.scss.min.ad03de1683bb39a0d1b31395797b97188e59cda6d778c0671a99db0b4fb799a9.css integrity="sha256-rQPeFoO7OaDRsxOVeXuXGI5ZzabXeMBnGpnbC0+3mak="><link rel=stylesheet type=text/css href=/css/tabs.scss.min.549aba196cc14bca7747a312ff35df0aa1f486b740c19ee0c88aaa721fb8c2e1.css integrity="sha256-VJq6GWzBS8p3R6MS/zXfCqH0hrdAwZ7gyIqqch+4wuE="><link rel=stylesheet href=/theme-css/backtotop.min.af4a1eb2a3e4e5ca38353a8320dafc9b1e1fd2edd480caa5fff0ae4e751d991c.css integrity="sha256-r0oesqPk5co4NTqDINr8mx4f0u3UgMql//CuTnUdmRw="><link rel=stylesheet href=/theme-css/bulma.min.f488b160722c9b7a2a760c03808dc8df5173e6c9dd25cb7481451ddb3c4f35dc.css integrity="sha256-9IixYHIsm3oqdgwDgI3I31Fz5sndJct0gUUd2zxPNdw="><link rel=stylesheet href=/theme-css/code-highlight.min.d0bd96ff1dbeb4b62536da5935b92af5cd7edb6d6f52b316d721e62078d9f089.css integrity="sha256-0L2W/x2+tLYlNtpZNbkq9c1+221vUrMW1yHmIHjZ8Ik="><link rel=stylesheet href=/theme-css/content.min.1de9b096ffc099fee4b538589fea6b622be33d69de64c451e11f2c91476029c5.css integrity="sha256-Hemwlv/Amf7ktThYn+prYivjPWneZMRR4R8skUdgKcU="><link rel=stylesheet href=/theme-css/dark-mode.min.1a7d04742ddf658331233b701507a0124657cbf45e02c672c061955181de6dde.css integrity="sha256-Gn0EdC3fZYMxIztwFQegEkZXy/ReAsZywGGVUYHebd4="><link rel=stylesheet href=/theme-css/footer.min.4be63c4d5628cb485efcfa5c9475fa1daa18933eb83741a2ca2bcd444ec270a2.css integrity="sha256-S+Y8TVYoy0he/PpclHX6HaoYkz64N0GiyivNRE7CcKI="><link rel=stylesheet href=/theme-css/hero.min.aa8286fd7d31d78e297e71594436c47b17d4f28660fd16f2b252e3f55fa500be.css integrity="sha256-qoKG/X0x144pfnFZRDbEexfU8oZg/RbyslLj9V+lAL4="><link rel=stylesheet href=/theme-css/lists.min.83821789384ebadc1a1ff75ef9f4b29ba53fe45eb30a46a228aa55772a393396.css integrity="sha256-g4IXiThOutwaH/de+fSym6U/5F6zCkaiKKpVdyo5M5Y="><link rel=stylesheet href=/theme-css/navbar.min.c15f7eadb5a7e1532309c04d94e1b0099d4fa75aaded30829bbfd21ebdb51ad5.css integrity="sha256-wV9+rbWn4VMjCcBNlOGwCZ1Pp1qt7TCCm7/SHr21GtU="><link rel=stylesheet href=/theme-css/news.min.8875ffae62ae22741a27025581fcb3341c18442be06bf132e45f8d6027692876.css integrity="sha256-iHX/rmKuInQaJwJVgfyzNBwYRCvga/Ey5F+NYCdpKHY="><link rel=stylesheet href=/theme-css/posts.min.9505f87d5973f3f08c99c613c0781b3a42411f4795657e8da7ef29c7ad37c23d.css integrity="sha256-lQX4fVlz8/CMmcYTwHgbOkJBH0eVZX6Np+8px603wj0="><link rel=stylesheet href=/theme-css/search.min.ee3423de82ad5535fd375aa47bc4fe618ecaa5d10eb0b68fe6dfc85a78790676.css integrity="sha256-7jQj3oKtVTX9N1qke8T+YY7KpdEOsLaP5t/IWnh5BnY="><link rel=stylesheet href=/theme-css/shortcuts.min.f90addf0a2a3c4e075eb5c3c78e4cc27d9b4fba18a02a17808695212762224c1.css integrity="sha256-+Qrd8KKjxOB161w8eOTMJ9m0+6GKAqF4CGlSEnYiJME="><link rel=stylesheet href=/theme-css/styles.min.00c75e5e25cb21123ca151cb4f4a130891157870829d91cefa425316ecf23de2.css integrity="sha256-AMdeXiXLIRI8oVHLT0oTCJEVeHCCnZHO+kJTFuzyPeI="><link rel=stylesheet href=/theme-css/tables.min.7a44b6bd698323dd3d379b714bd534132e76bf4ba0d3dec61997a8d9ba9db5fb.css integrity="sha256-ekS2vWmDI909N5txS9U0Ey52v0ug097GGZeo2bqdtfs="><link rel=stylesheet href=/theme-css/tabs.min.8884c317231b5f2331b2fd9f65e4f7900fe9124aafae93b78cef175960289683.css integrity="sha256-iITDFyMbXyMxsv2fZeT3kA/pEkqvrpO3jO8XWWAoloM="><link rel=stylesheet href=/theme-css/vars.min.3d537d14ea6e6fb59012fa9d357adf4b209dab8c2535fb94ab37afb6a37020fd.css integrity="sha256-PVN9FOpub7WQEvqdNXrfSyCdq4wlNfuUqzevtqNwIP0="><link rel=stylesheet href=/css/casestudies.min.92b0bafc1e58181b02c23f14b861767269e505eadc85a123b4eb79e2527bf2e0.css integrity="sha256-krC6/B5YGBsCwj8UuGF2cmnlBerchaEjtOt54lJ78uA="><link rel=stylesheet href=/css/custom.min.cf0f0187caa046832f55197d09d0ad54a98eebc7758bbb354fb1c8fb8541b5bb.css integrity="sha256-zw8Bh8qgRoMvVRl9CdCtVKmO68d1i7s1T7HI+4VBtbs="><link rel=stylesheet href=/css/mailchimp.min.96f403ea4c8be10747beb4c33a219da2fa8234a3b98882983bd2569da8eeb9e1.css integrity="sha256-lvQD6kyL4QdHvrTDOiGdovqCNKO5iIKYO9JWnajuueE="><link rel=stylesheet href=/css/shell.min.173478d133f6f5990705f3ed2f48714422de15754d813df6aa2a047bf62a51da.css integrity="sha256-FzR40TP29ZkHBfPtL0hxRCLeFXVNgT32qioEe/YqUdo="><script src=https://code.jquery.com/jquery-3.7.1.min.js></script><link rel=alternate hreflang=en href=/case-studies/deeplabcut-dnn/ title=English><link rel=alternate hreflang=pt href=/pt/case-studies/deeplabcut-dnn/ title=Português><link rel=alternate hreflang=ja href=/ja/case-studies/deeplabcut-dnn/ title="日本語 (Japanese)"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://numpy.org/images/numpy-image.jpg"><meta name=twitter:title content="Caso de estudio: DeepLabCut Estimación de Postura 3D"><meta name=twitter:description content="Analizar movimiento de las manos de los ratones usando DeepLapCut#
(Fuente: www.deeplabcut.org ) El software de código abierto está acelerando la biomedicina. DeepLabCut permite el análisis automatizado de video del comportamiento animal utilizando Aprendizaje Profundo. —Alexander Mathis, Profesor Asistente, Escuela Politécnica Federal de Lausana (EPFL)
Acerca de DeepLabCut# DeepLabCut es una caja de herramientas de código abierto que permite a los investigadores de cientos de instituciones de todo el mundo rastrear el comportamiento de animales de laboratorio, con muy pocos datos de entrenamiento, con una precisión de nivel humana. Con la tecnología DeepLabCut, los científicos pueden profundizar en la comprensión científica del control motriz y el comportamiento a través de especies animales y escalas temporales."></head><body><nav id=nav class=navbar role=navigation aria-label="main navigation"><div class=container><div class=navbar-brand><a class=navbar-item href=/es/><img class=navbar-logo src=/images/logo.svg alt="%!s(<nil>) logo"><div class=navbar-logo-text>NumPy</div></a><a role=button class=navbar-burger aria-label=menu aria-expanded=false data-target=navbar-menu><span aria-hidden=true></span>
<span aria-hidden=true></span>
<span aria-hidden=true></span></a></div><div id=navbar-menu class=navbar-menu><div class=navbar-end><a href=/es/install class=navbar-item>Instalar
</a><a href=https://numpy.org/doc/stable class=navbar-item>Documentación
</a><a href=/es/learn class=navbar-item>Aprende
</a><a href=/es/community class=navbar-item>Comunidad
</a><a href=/es/about class=navbar-item>Quiénes somos
</a><a href=/es/news class=navbar-item>Noticias
</a><a href=/es/contribute class=navbar-item>Contribuye</a><div class="navbar-item has-dropdown"><a aria-label="Select language" class=navbar-link>Español</a><div class=navbar-dropdown><a href=/case-studies/deeplabcut-dnn/ class=navbar-item>English
</a><a href=/pt/case-studies/deeplabcut-dnn/ class=navbar-item>Português
</a><a href=/ja/case-studies/deeplabcut-dnn/ class=navbar-item>日本語 (Japanese)</a></div></div></div></div></div></nav><section class=content-padding><div class=content-container><nav aria-label=Breadcrumb><ul id=breadcrumbs class=bd-breadcrumbs><li class="breadcrumb-item breadcrumb-home"><a href=/es/ class=nav-link aria-label=Home><i class="fas fa-home"></i></a></li><li class=breadcrumb-item><a href=/es/case-studies/ class=nav-link>Case-Studies</a></li><li class="breadcrumb-item active" aria-current=page>Caso de estudio: DeepLabCut Estimación de Postura 3D</li></ul></nav><h1>Caso de estudio: DeepLabCut Estimación de Postura 3D</h1><div><figure class=align-default id=id000><img src=/images/content_images/cs/mice-hand.gif alt=micehandanim class=align-center><figcaption><strong class=caption-title>Analizar movimiento de las manos de los ratones usando DeepLapCut</strong><a class=headerlink href=#id000 title="Link to this image">#</a><br><a href=http://www.mousemASElab.org/deeplabcut>(Fuente: www.deeplabcut.org )</a><p><span class=caption-text></span></figcaption></figure><blockquote cite=https://news.harvard.edu/gazette/story/newsplus/harvard-researchers-awarded-czi-open-source-award/><p>El software de código abierto está acelerando la biomedicina. DeepLabCut permite el análisis automatizado de video del comportamiento animal utilizando Aprendizaje Profundo.</p><p class=attribution>—Alexander Mathis, <em>Profesor Asistente, Escuela Politécnica Federal de Lausana</em> (<a href=https://www.epfl.ch/en/>EPFL</a>)</p></blockquote><h2 id=acerca-de-deeplabcut>Acerca de DeepLabCut<a class=headerlink href=#acerca-de-deeplabcut title="Link to this heading">#</a></h2><p><a href=https://github.com/DeepLabCut/DeepLabCut>DeepLabCut</a> es una caja de herramientas de código abierto que permite a los investigadores de cientos de instituciones de todo el mundo rastrear el comportamiento de animales de laboratorio, con muy pocos datos de entrenamiento, con una precisión de nivel humana. Con la tecnología DeepLabCut, los científicos pueden profundizar en la comprensión científica del control motriz y el comportamiento a través de especies animales y escalas temporales.</p><p>Muchas áreas de investigación, incluyendo la neurociencia, la medicina y la biomecánica, utilizan datos para rastrear el movimiento animal. DeepLabCut ayuda a entender lo que los humanos y otros animales están haciendo, analizando las acciones que han sido grabadas en la filmación. Utilizando la automatización para tareas laboriosas de etiquetado y monitoreo, junto con el análisis de datos basado en redes neuronales profundas, DeepLabCut realiza estudios científicos que involucran la observación de animales, tales como primates, ratones, peces, moscas, etc. de manera mucho más rápida y precisa.</p><figure class=align-default id=id002><img src=/images/content_images/cs/race-horse.gif alt=horserideranim class=align-center><figcaption><strong class=caption-title>Puntos de colores rastrean las posiciones de una parte del cuerpo de un caballo de carreras</strong><a class=headerlink href=#id002 title="Link to this image">#</a><br>(Fuente: Mackenzie Mathis)<p><span class=caption-text></span></figcaption></figure><p>El rastreo del comportamiento no invasivo de animales de DeepLabCut por medio de la extracción de posturas de animales es crucial para propósitos científicos en dominios tales como la biomecánica, genética, etología y & neurociencia. Medir las poses de animales de manera no invasiva a partir de video - sin marcadores - en fondos que cambian dinámicamente es un desafío computacional, tanto técnicamente como en términos de necesidades de recursos y datos de entrenamiento requeridos.</p><p>DeepLabCut permite a los investigadores estimar la postura del sujeto, permitiéndoles eficientemente cuantificar el comportamiento a través de una caja de herramientas de software basada en Python. Con DeepLabCut, los investigadores pueden identificar fotogramas distintos de videos, etiquetar digitalmente partes específicas del cuerpo en unas pocas docenas de fotogramas con una GUI personalizada, y luego las arquitecturas de estimación de posturas basadas en aprendizaje profundo en DeepLabCut aprenden a identificar esas mismas características en el resto del video y en otros videos similares de animales. Funciona en diferentes especies de animales, desde los animales de laboratorio comunes como moscas y ratones hasta animales más inusuales como los <a href=https://www.technologynetworks.com/neuroscience/articles/interview-a-deeper-cut-into-behavior-with-mackenzie-mathis-327618>guepardos</a>.</p><p>DeepLabCut utiliza un principio llamado <a href=https://arxiv.org/pdf/1909.11229>aprendizaje por transferencia</a>, que reduce considerablemente la cantidad de datos de entrenamiento requeridos y acelera la convergencia del período de entrenamiento. Dependiendo de las necesidades, los usuarios pueden seleccionar diferentes arquitecturas de red que proporcionan una inferencia más rápida (por ejemplo MobileNetV2), que también pueden combinarse con retroalimentación experimental en tiempo real. DeepLabCut utilizó originalmente los detectores de características de una arquitectura de estimación de postura humana de alto rendimiento, llamada <a href=https://arxiv.org/abs/1605.03170>DeeperCut</a>, que inspiró el nombre. El paquete ahora ha sido significativamente modificado para incluir arquitecturas adicionales, métodos de aumento y una experiencia de usuario completa en el front-end. Además, para apoyar los experimentos biológicos a gran escala, DeepLabCut proporciona capacidades de aprendizaje activo para que los usuarios puedan aumentar el conjunto de entrenamiento a lo largo del tiempo para cubrir casos límite y hacer que su algoritmo de estimación de postura sea robusto dentro de un contexto específico.</p><p>Recientemente, se presentó el <a href=http://www.mousemotorlab.org/dlc-modelzoo>modelo zoo de DeepLabCut</a>, que proporciona modelos pre-entrenados para varias especies y condiciones experimentales, desde el análisis facial en primates hasta la postura de perro. Esto se puede ejecutar, por ejemplo, en la nube sin ningún etiquetado de datos nuevos o entrenamiento de redes neuronales, y no es necesaria ninguna experiencia de programación.</p><h3 id=objetivos-y-resultados-clave>Objetivos y Resultados Clave<a class=headerlink href=#objetivos-y-resultados-clave title="Link to this heading">#</a></h3><ul><li><p><strong>Automatización del análisis de la postura animal para estudios científicos:</strong></p><p>El objetivo principal de la tecnología DeepLabCut es medir y rastrear la postura de los animales en diversos entornos. Estos datos se pueden utilizar, por ejemplo, en estudios de neurociencia para entender cómo el cerebro controla el movimiento, o para aclarar como interactúan socialmente los animales. Los investigadores han observado un <a href=https://www.biorxiv.org/content/10.1101/457242v1>aumento de rendimiento diez veces mayor</a> con DeepLabCut. Las posturas se pueden inferir sin conexión hasta a 1200 fotogramas por segundo (FPS).</p></li><li><p><strong>Creación de un conjunto de herramientas de Python de fácil uso para la estimación de postura:</strong></p><p>DeepLabCut quería compartir su tecnología de estimación de postura animal en la forma de una herramienta de fácil uso que pueda ser adoptada fácilmente por los investigadores. Así que han creado un conjunto de herramientas de Python completo y de fácil uso, también con características de administración de proyectos. Estas permiten no solo la automatización de la estimación de postura, sino también administrar el proyecto de punta a punta ayudando al usuario del conjunto de herramientas de DeepLabCut desde la etapa de recolección del conjunto de datos para crear flujos de trabajo de análisis compartibles y reutilizables.</p><p>Su <a href=https://github.com/DeepLabCut/DeepLabCut>conjunto de herramientas</a> ahora está disponible como código abierto.</p><p>En flujo de trabajo típico de DeepLabCut incluye:</p><ul><li>creación y refinamiento de los conjuntos de entrenamiento a través del aprendizaje activo</li><li>creación de redes neuronales a la medida para animales y escenarios específicos</li><li>código para inferencia a gran escala en videos</li><li>graficar las inferencias utilizando herramientas de visualización integradas</li></ul></li></ul><figure class=align-center id=id003><img src=/images/content_images/cs/deeplabcut-toolkit-steps.png alt=dlcsteps class=align-center><figcaption><strong class=caption-title>Pasos de estimación de la postura con DeepLabCut</strong><a class=headerlink href=#id003 title="Link to this image">#</a><br><a href=https://twitter.com/DeepLabCut/status/1198046918284210176/photo/1>(Source: DeepLabCut)</a><p><span class=caption-text></span></figcaption></figure><h3 id=los-desafíos>Los Desafíos<a class=headerlink href=#los-desafíos title="Link to this heading">#</a></h3><ul><li><p><strong>Velocidad</strong></p><p>Procesamiento rápido de videos de comportamiento animal para medir su comportamiento y al mismo tiempo hacer experimentos científicos más eficientes y precisos. La extracción detallada de posturas del animal para experimentos de laboratorio, sin marcadores, en entornos dinámicamente cambiantes, puede ser un desafío tanto técnico como en términos de recursos necesarios y datos de entrenamiento requeridos. Proponer una herramienta que sea fácil de usar sin necesidad de habilidades como experiencia en visión por computador que permita a los científicos hacer investigaciones en más contextos del mundo real, es un problema que no es trivial de resolver.</p></li><li><p><strong>Combinatoria</strong></p><p>La combinatoria involucra el armado e integración del movimiento de múltiples extremidades en el comportamiento animal individual. Ensamblar puntos clave y sus conexiones en movimientos individuales de animales y vincularlos a lo largo del tiempo es un proceso complejo que requiere un análisis numérico intensivo, especialmente en el caso del seguimiento de movimientos de múltiples animales en videos de experimentos.</p></li><li><p><strong>Procesamiento de Datos</strong></p><p>Por último, pero no menos importante, la manipulación de arreglos - procesamiento de grandes pilas de arreglos correspondientes a varias imágenes, tensores objetivo y puntos clave es bastante desafiante.</p></li></ul><figure class=align-center id=id004><img src=/images/content_images/cs/pose-estimation.png alt=challengesfig class=align-center><figcaption><strong class=caption-title>Estimación de variedad y complejidad de postura</strong><a class=headerlink href=#id004 title="Link to this image">#</a><br><a href=https://www.iorxiv.org/content/10.1101/476531v1.full.pdf>(Fuente: Mackenzie Mathis)</a><p><span class=caption-text></span></figcaption></figure><h2 id=el-papel-de-numpy-para-afrontar-los-desafíos-de-la-estimación-de-postura>El Papel de NumPy para afrontar los desafíos de la estimación de postura<a class=headerlink href=#el-papel-de-numpy-para-afrontar-los-desafíos-de-la-estimación-de-postura title="Link to this heading">#</a></h2><p>NumPy aborda la necesidad central de la tecnología de DeepLabCut de realizar cálculos numéricos a alta velocidad para el análisis del comportamiento. Además de NumPy, DeepLabCut emplea varios softwares de Python que utilizan NumPy en su núcleo, como <a href=https://www.scipy.org>SciPy</a>, <a href=https://pandas.pydata.org>Pandas</a>, <a href=https://matplotlib.org>matplotlib</a>, <a href=https://github.com/tensorpack/tensorpack>Tensorpack</a>, <a href=https://github.com/aleju/imgaug>imgaug</a>, <a href=https://scikit-learn.org/stable/>scikit-learn</a>, <a href=https://scikit-image.org>scikit-image</a> y <a href=https://www.tensorflow.org>Tensorflow</a>.</p><p>Las siguientes características de NumPy jugaron un papel clave en abordar el procesamiento de imágenes, los requisitos de combinatoria y la necesidad de cálculos rápidos en los algoritmos de estimación de posturas de DeepLabCut:</p><ul><li>Vectorización</li><li>Operaciones con Arreglos Enmascarados</li><li>Álgebra lineal</li><li>Muestreo Aleatorio</li><li>Redimensionamiento de arreglos grandes</li></ul><p>DeepLabCut utiliza las capacidades de arreglos de NumPy a lo largo del flujo de trabajo ofrecido por el conjunto de herramientas. En particular, NumPy se utiliza para muestrear diferentes fotogramas para etiquetado de anotaciones humanas, y para escribir, editar y procesar datos de anotación. Dentro de TensorFlow, la red neuronal es entrenada por la tecnología DeepLabCut durante miles de iteraciones para predecir las anotaciones de referencia a partir de fotogramas. Para este propósito, se crean densidades objetivo (mapas de puntuación) para plantear la estimación de poses como un problema de traducción de imagen a imagen. Para hacer que las redes neuronales sean robustas, se emplea el aumento de datos, lo que requiere el cálculo de mapas de puntuación objetivo sujetos a varios pasos geométricos y de procesamiento de imágenes. Para hacer que el entrenamiento sea rápido, se aprovechan las capacidades de vectorización de NumPy. Para la inferencia, es necesario extraer las predicciones más probables de los mapas de puntuación objetivo y &ldquo;vincular eficientemente las predicciones para ensamblar animales individuales&rdquo;.</p><figure class=align-default id=id005><img src=/images/content_images/cs/deeplabcut-workflow.png alt="flujo de trabajo" class=align-center><figcaption><strong class=caption-title>Flujo de Trabajo de DeepLabCut</strong><a class=headerlink href=#id005 title="Link to this image">#</a><br><a href=https://www.researchgate.net/figure/DeepLabCut-work-flow-The-diagram-delineates-the-work-flow-as-well-as-the-directory-and_fig1_329185962>(Fuente: Mackenzie Mathis)</a><p><span class=caption-text></span></figcaption></figure><h2 id=resumen>Resumen<a class=headerlink href=#resumen title="Link to this heading">#</a></h2><p>Observar y describir eficientemente el comportamiento es un punto central de la etología moderna, neurociencia, medicina y tecnología. <a href=http://orga.cvss.cc/wp-content/uploads/2019/05/NathMathis2019.pdf>DeepLabCut</a> permite a los investigadores estimar la postura del sujeto, permitiéndoles de manera eficiente cuantificar el comportamiento. Con solo un pequeño conjunto de imágenes de entrenamiento, el conjunto de herramientas de Python de DeepLabCut permite entrenar una red neuronal con una precisión de etiquetado a nivel humano, expandiendo así su aplicación no solo al análisis del comportamiento en el laboratorio, sino también potencialmente en deportes, análisis de marcha, medicina y estudios de rehabilitación. Los desafíos de la combinatoria compleja y procesamiento de datos enfrentados por los algoritmos de DeepLabCut se abordan mediante el uso de las capacidades de manipulación de arreglos de NumPy.</p><figure class=align-default id=id006><img src=/images/content_images/cs/numpy_dlc_benefits.png alt="beneficios de NumPy" class=align-center><figcaption><strong class=caption-title>Capacidades claves utilizadas de NumPy</strong><a class=headerlink href=#id006 title="Link to this image">#</a><br><p><span class=caption-text></span></figcaption></figure></div></div><div id=shortcuts-container><div id=shortcuts><div id=shortcuts-header><i class="fa-solid fa-list"></i> On this page</div></div></div></section><div id=backtotop><a href=# id=backtotop-color><i class="fa-solid fa-arrow-up"></i></a></div><footer id=footer><div class=container><div id=footer-columns><div id=footer-logo-column><img id=footer-logo src=/images/logo.svg alt="NumPy logo. "></div><div class=footer-column><div class=footer-item><a href=/es/install>Instalar</a></div><div class=footer-item><a href=https://numpy.org/doc/stable>Documentación</a></div><div class=footer-item><a href=/es/learn>Aprende</a></div><div class=footer-item><a href=/es/citing-numpy>Citando a NumPy</a></div><div class=footer-item><a href=https://numpy.org/neps/roadmap.html>Mapa de ruta</a></div></div><div class=footer-column><div class=footer-item><a href=/es/about>Acerca de nosotros</a></div><div class=footer-item><a href=/es/community>Comunidad</a></div><div class=footer-item><a href=/es/user-surveys>Encuestas a usuarios</a></div><div class=footer-item><a href=/es/contribute>Contribuye</a></div><div class=footer-item><a href=/es/code-of-conduct>Código de Conducta</a></div></div><div class=footer-column><div class=footer-item><a href=/es/gethelp>Buscar ayuda</a></div><div class=footer-item><a href=/es/terms>Términos de uso</a></div><div class=footer-item><a href=/es/privacy>Confidencialidad</a></div><div class=footer-item><a href=/es/press-kit>Kit de prensa</a></div></div><div class=footer-actions>Sign up for the latest NumPy news, resources, and more<form action="https://numpy.us4.list-manage.com/subscribe/post?u=5ddd0d1d6e807900a8212481a&amp;id=287fa4253c" method=post id=mc-embedded-subscribe-form name=mc-embedded-subscribe-form class="validate sign-up-container" target=_blank novalidate><div class=sign-up-image><svg class="icon mail-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M22 6c0-1.1-.9-2-2-2H4c-1.1.0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1.0 2-.9 2-2V6zm-2 0-8 5-8-5h16zm0 12H4V8l8 5 8-5v10z"/></svg></div><input type=email name=EMAIL class="required email sign-up-input" id=mce-EMAIL aria-label="Input for email, press enter to submit" onkeypress='(event.which===13||event.keyCode===13||event.key==="Enter")&&sendThankYou()'><div class=submission-instructions>Press Enter</div><button class=signup-button onclick=sendThankYou() aria-label=Submit><svg class="icon sent-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M2.01 21 23 12 2.01 3 2 10l15 2-15 2z"/></svg></button><div id=mce-responses class=clear><div class=response id=mce-error-response style=display:none></div><div class=response id=mce-success-response style=display:none></div></div><div style=position:absolute;left:-5000px aria-hidden=true><input type=text name=b_5ddd0d1d6e807900a8212481a_287fa4253c tabindex=-1></div><div class=clear><input type=submit value=Subscribe name=subscribe id=mc-embedded-subscribe class=button style=display:none></div></form><div class=thank-you>Thank you! &#127881;</div><div class=community-icons><a href=https://github.com/numpy/numpy aria-label=https://github.com/numpy/numpy><svg class="icon github-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M12 .297c-6.63.0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577.0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93.0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176.0.0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22.0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22.0 1.606-.015 2.896-.015 3.286.0.315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
</a><a href=https://www.youtube.com/channel/UCguIL9NZ7ybWK5WQ53qbHng aria-label=https://www.youtube.com/channel/UCguIL9NZ7ybWK5WQ53qbHng><svg class="icon youtube-icon" viewBox="0 0 24 24" viewBox="0 0 24 24"><path d="M23.498 6.186A3.016 3.016.0 0021.376 4.05C19.505 3.545 12 3.545 12 3.545s-7.505.0-9.377.505A3.017 3.017.0 00.502 6.186C0 8.07.0 12 0 12s0 3.93.502 5.814a3.016 3.016.0 002.122 2.136c1.871.505 9.376.505 9.376.505s7.505.0 9.377-.505a3.015 3.015.0 002.122-2.136C24 15.93 24 12 24 12s0-3.93-.502-5.814zM9.545 15.568V8.432L15.818 12l-6.273 3.568z"/></svg></a></div><div class=copyright>&copy; 2025 NumPy team. All rights reserved.</div></div></div></div></footer></body><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin=anonymous referrerpolicy=no-referrer><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css integrity="sha512-Kc323vGBEqzTmouAECnVceyQqyqdsSiqLQISBL29aUW4U/M7pSPA/gEUZQqv1cwx4OnYxTxve5UMg5GT6L4JJg==" crossorigin=anonymous referrerpolicy=no-referrer><script type=text/javascript src=/js/bundle.min.js></script><script type=text/javascript>setupShortcuts(maxLevel=2)</script><script defer data-domain=numpy.org src=https://views.scientific-python.org/js/script.js></script></html>